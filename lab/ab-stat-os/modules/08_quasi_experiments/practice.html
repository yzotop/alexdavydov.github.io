<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Практика — Модуль 8. A/B без A/B</title>
    <link rel="stylesheet" href="../../assets/style.css">
</head>
<body>
    <div class="container">
        <div class="breadcrumbs">
            <a href="../../../../courses/index.html">Все курсы</a> /
            <a href="../../index.html">Статистика A/B-тестирования</a> /
            <a href="./index.html">Модуль 8</a> / Практика
        </div>
        <div class="nav-links">
            <a href="./index.html">Модуль</a>
            <a href="./practice.html" class="active">Практика</a>
            <a href="./simulators.html">Симуляторы</a>
        </div>
        <h1>Практика</h1>
        <p class="subtitle">Для каждой задачи выберите подходящий квази-экспериментальный метод, сформулируйте допущения и продумайте проверки, которые защитят вас от ложных выводов.</p>

        <!-- Task 1 -->
        <div class="task-card">
            <div class="task-title">Задача 1. Запуск в одном городе (DiD)</div>
            <div class="task-body">
                <p>Сервис доставки запускает услугу «доставка в тот же день» только в Новосибирске. В остальных городах ничего не меняют.</p>
                <p>У вас есть 8 недель данных по выручке на пользователя для всех городов до запуска и несколько недель после.</p>
                <p>Бизнес хочет оценить, насколько услуга увеличила выручку именно в Новосибирске.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> Difference-in-Differences (DiD) с treated-группой «Новосибирск» и набором похожих городов в контроле.</p>
                    <p><strong>Ключевое допущение:</strong> без запуска услуги тренды выручки в Новосибирске и контрольных городах шли бы параллельно.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Нарисовать pre-period тренды по городам и проверить визуально параллельность.</li>
                        <li>Сделать placebo DiD с ложной датой запуска (например, на 4 недели раньше) — эффект должен быть близок к нулю.</li>
                        <li>Проверить, не было ли в Новосибирске локальных акций или PR-кампаний, которых нет в контроле.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> специфический шок в Новосибирске (локальная промоакция, конкуренты, погода), который ломает параллельные тренды и «подмешивается» в оценку эффекта.</p>
                </div>
            </details>
        </div>

        <!-- Task 2 -->
        <div class="task-card">
            <div class="task-title">Задача 2. Premium для «активных» пользователей (Matching)</div>
            <div class="task-body">
                <p>Продуктовая команда вручную включила премиум-функции пользователям, у которых было &gt; 50 заказов за всё время.</p>
                <p>Теперь вы хотите оценить влияние премиума на удержание через 3 месяца. Рандомизации не было, эксперимент задним числом.</p>
                <p>Есть полная история заказов, регистраций, устройств и регионов по всем пользователям.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> matching / reweighting (propensity score matching или IPW) с treated-группой «получили премиум» и контролем «похожий профиль, но без премиума».</p>
                    <p><strong>Ключевое допущение:</strong> selection on observables — все факторы, влияющие на выдачу премиума и удержание, наблюдаемы (например, активность, стаж, тип устройства).</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Построить модель пропенсити и проверить баланс признаков после matching (standardized differences &lt; 0.1).</li>
                        <li>Убедиться, что используете только pre-treatment признаки (до выдачи премиума), а не метрики периода измерения эффекта.</li>
                        <li>Сравнить результаты разных спецификаций matching (nearest neighbor, caliper, разные наборы ковариат).</li>
                    </ul>
                    <p><strong>Главный риск:</strong> немеряемая мотивация или лояльность: пользователи, которым дали премиум, могут отличаться по «внутренним» характеристикам даже при совпадающих наблюдаемых признаках, что приведёт к завышению эффекта.</p>
                </div>
            </details>
        </div>

        <!-- Task 3 -->
        <div class="task-card">
            <div class="task-title">Задача 3. Feature launch в одной стране (Synthetic control)</div>
            <div class="task-body">
                <p>Новый алгоритм рекомендаций запустили только в Германии. Ещё 12 европейских стран работают по старой схеме.</p>
                <p>У вас есть 6 месяцев помесячных данных по выручке и DAU до запуска и несколько месяцев после.</p>
                <p>Цель — понять, насколько именно алгоритм изменил метрики в Германии, учитывая общерыночные тренды.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> synthetic control: построить «синтетическую Германию» из контрольных стран (Франция, Испания, Италия и др.).</p>
                    <p><strong>Ключевое допущение:</strong> существует такая комбинация контрольных стран, которая хорошо воспроизводит тренд Германии до запуска; без алгоритма Германия продолжила бы вести себя как эта комбинация.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Проверить качество подгона в pre-period (RMSE, визуальное совпадение кривых treated и synthetic).</li>
                        <li>Запустить placebo-анализы: применить synthetic control к другим странам, где не было запуска, и убедиться, что там эффект ≈ 0.</li>
                        <li>Проверить устойчивость эффекта к исключению отдельных доноров и изменению набора ковариат.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> Германия имела свой уникальный тренд, плохо воспроизводимый донорским пулом, либо в Германии были специфические события (регуляция, кризис), которых нет в донорах — тогда контрфактуал ненадёжен.</p>
                </div>
            </details>
        </div>

        <!-- Task 4 -->
        <div class="task-card">
            <div class="task-title">Задача 4. Промо-порог (RDD)</div>
            <div class="task-body">
                <p>Пользователи, которые тратят &gt; 10 000 ₽ в месяц, автоматически получают 5% cashback на следующий месяц.</p>
                <p>Нужно оценить, увеличивает ли cashback траты в следующем месяце. Чёткого A/B нет: правило действует для всех.</p>
                <p>Доступны точные помесячные траты по пользователям за несколько месяцев.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> Regression Discontinuity Design (RDD) вокруг порога 10 000 ₽.</p>
                    <p><strong>Ключевое допущение:</strong> пользователи не могут точно манипулировать месячными тратами относительно порога, и пользователи с тратами чуть выше и чуть ниже 10 000 ₽ сравнимы по всем прочим факторам.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Построить гистограмму трат около 10 000 ₽ и проверить отсутствие явного бучинга или провалов.</li>
                        <li>Проверить баланс основных ковариат (стаж, страна, устройство) слева и справа от порога в узком окне.</li>
                        <li>Протестировать устойчивость оценки эффекта к разным bandwidth и спецификациям регрессии.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> пользователи специально «добивают» покупки до порога, а также малая плотность наблюдений в окрестности 10 000 ₽, из-за чего оценка становится шумной.</p>
                </div>
            </details>
        </div>

        <!-- Task 5 -->
        <div class="task-card">
            <div class="task-title">Задача 5. Компания целиком перешла на новый дизайн (ITS)</div>
            <div class="task-body">
                <p>Мобильное приложение полностью обновило дизайн и навигацию для всех пользователей в один день. Holdout-группы нет.</p>
                <p>У вас есть 12 недель данных по DAU, конверсии и выручке до редизайна и 8 недель после.</p>
                <p>Команда хочет понять, не «убили» ли редизайном основные продуктовые метрики.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> Interrupted Time Series (ITS) / CausalImpact с моделированием временного ряда по pre-period и оценкой отклонения постпериода от прогноза.</p>
                    <p><strong>Ключевое допущение:</strong> модель временного ряда хорошо описывает метрику без редизайна; других крупных изменений в момент запуска нет.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Проверить остатки модели на pre-period (нет ли систематических паттернов, сезонность хорошо отловлена).</li>
                        <li>Проанализировать календарь: не запускались ли одновременно крупные маркетинговые кампании, промо, изменения цен.</li>
                        <li>Построить альтернативные модели (с/без контрольных рядов, разные структуры сезонности) и сравнить устойчивость оценок эффекта.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> наложение нескольких событий (кампания, новый тариф, PR-кризис), которые модель интерпретирует как эффект редизайна.</p>
                </div>
            </details>
        </div>

        <!-- Task 6 -->
        <div class="task-card">
            <div class="task-title">Задача 6. DiD с нарушенными parallel trends ⚠</div>
            <div class="task-body">
                <p>Вы построили DiD: Москва — treatment (запуск новой логистики), Санкт-Петербург — контроль.</p>
                <p>Эффект получился +7% к выручке. Но при проверке выяснилось, что в pre-period Москва росла на 3 п.п. в неделю быстрее, чем СПб.</p>
                <p>Графики явно расходятся ещё до запуска.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый вывод:</strong> ключевое допущение DiD (параллельные тренды) нарушено, оценка эффекта смещена. Интерпретировать +7% как эффект логистики нельзя.</p>
                    <p><strong>Ключевое допущение:</strong> без логистики gap между Москвой и СПб оставался бы примерно постоянным или предсказуемым; наблюдаемый разъезд трендов показывает, что это не так.</p>
                    <p><strong>Sanity checks и возможные фиксы:</strong></p>
                    <ul>
                        <li>Поиск другой контрольной группы: набор городов с трендом, более похожим на Москву до запуска.</li>
                        <li>Попробовать synthetic control для Москвы, используя несколько городов-доноров вместо одного СПб.</li>
                        <li>Сделать placebo DiD на pre-period с ложной датой запуска и убедиться, что «эффект» там тоже заметен — это аргумент против текущего дизайна.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> бизнес может принять решение на основе смещённой оценки, переоценив эффект логистики и недооценив другие факторы роста Москвы.</p>
                </div>
            </details>
        </div>

        <!-- Task 7 -->
        <div class="task-card">
            <div class="task-title">Задача 7. Matching по post-treatment переменной ⚠</div>
            <div class="task-body">
                <p>Аналитик оценивал эффект новой программы лояльности. Он матчил пользователей по «числу покупок за период эксперимента» и другим признакам.</p>
                <p>После matching среднее число покупок почти совпало между treated и control, и эффект по выручке оказался близок к нулю.</p>
                <p>Руководитель радуется: «Программа лояльности ничего не даёт, можно не масштабировать».</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Проблема:</strong> использован post-treatment признак (число покупок во время эксперимента) в процедуре matching. Эта переменная сама зависит от treatment, и matching на ней «выравнивает» именно эффект.</p>
                    <p><strong>Ключевое допущение (которое нарушено):</strong> matching должен использовать только pre-treatment ковариаты, которые не изменяются под действием treatment.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Проверить список признаков matching и убедиться, что все они измерены до запуска программы.</li>
                        <li>Перестроить matching, исключив post-treatment переменные, и сравнить оценку эффекта.</li>
                        <li>Проанализировать распределение числа покупок в treated и control до matching: именно там ожидается разница.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> недооценка эффекта программы лояльности и ошибочное решение свернуть её, хотя при корректном анализе эффект может быть существенным.</p>
                </div>
            </details>
        </div>

        <!-- Task 8 -->
        <div class="task-card">
            <div class="task-title">Задача 8. Synthetic control — плохой fit ⚠</div>
            <div class="task-body">
                <p>Вы построили synthetic Germany из других европейских стран. В pre-period среднеквадратичная ошибка (RMSE) между Германией и synthetic Germany составляет ~15% от среднего уровня выручки.</p>
                <p>В постпериод визуально есть небольшое отставание synthetic Germany от фактической Германии на уровне ~5%.</p>
                <p>Руководитель спрашивает: «Можно ли считать, что эффект алгоритма +5%?».</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Проблема:</strong> качество fit в pre-period слишком плохое. Ошибка 15% от среднего уровня метрики — это шум гораздо большего масштаба, чем наблюдаемый «эффект» 5%.</p>
                    <p><strong>Ключевое допущение:</strong> synthetic control должен хорошо воспроизводить treated-единицу до вмешательства; тогда отклонения после можно интерпретировать как эффект.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Пересчитать RMSE и относительную ошибку в pre-period, сравнить их с оцененным эффектом в постпериод.</li>
                        <li>Попробовать другие наборы доноров и ковариат, чтобы улучшить fit, либо честно зафиксировать, что это не удаётся.</li>
                        <li>Провести placebo-аналоги на других странах и посмотреть, не возникают ли такие же «эффекты» размера 5% там, где ничего не запускали.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> неверная каузальная интерпретация артефактов модели: при таком уровне шума 5% могут быть просто случайным отклонением, а не эффектом фичи.</p>
                </div>
            </details>
        </div>

        <!-- Task 9 -->
        <div class="task-card">
            <div class="task-title">Задача 9. RDD — манипуляция порогом ⚠</div>
            <div class="task-body">
                <p>Компания присваивает VIP-статус пользователям с числом покупок &gt;= 100. Вы хотите использовать RDD, чтобы оценить влияние VIP-статуса на выручку.</p>
                <p>Гистограмма числа покупок показывает резкий всплеск в интервале 99–101: пользователей с 99 и 100 покупками заметно больше, чем ожидается по тренду.</p>
                <p>Также часть менеджеров может вручную «доначислять» покупки важным клиентам.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Проблема:</strong> явная манипуляция running variable около порога. Пользователи и/или система подталкивают счетчик покупок к 100, чтобы получить VIP-статус.</p>
                    <p><strong>Ключевое допущение (которое рушится):</strong> пользователи не могут точно контролировать положение относительно порога, а распределение running variable гладкое около cutoff-а.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Формально провести тесты на бучинг (например, McCrary test) и визуально оценить распределение около 100.</li>
                        <li>Проверить, какие пользователи попали в зону 99–101 и не связаны ли они с особыми кампаниями или ручными действиями.</li>
                        <li>Рассмотреть альтернативные дизайны (matching, DiD с временной динамикой статуса), не опирающиеся на строгую RDD.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> RDD даёт сильно смещённую оценку эффекта, потому что выборка около порога уже не квазислучайная — там собраны «особые» пользователи, которых система или люди подталкивали к VIP.</p>
                </div>
            </details>
        </div>

        <!-- Task 10 -->
        <div class="task-card">
            <div class="task-title">Задача 10. Множественные интервенции (ITS)</div>
            <div class="task-body">
                <p>Компания в течение двух недель запустила сразу три изменения:</p>
                <p>1 марта — редизайн приложения, 5 марта — большую маркетинговую кампанию, 10 марта — повышение цен.</p>
                <p>У вас есть поминутные и подневные данные по DAU и выручке. Руководство просит «оценить эффект именно редизайна».</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Проблема:</strong> множественные интервенции, происходящие почти одновременно. ITS/ CausalImpact с одним «переломом» не сможет чисто отделить эффект редизайна от кампании и изменения цен.</p>
                    <p><strong>Ключевое допущение ITS:</strong> в момент интервенции происходит одно основное изменение, а остальные факторы фиксированы или учтены в модели.</p>
                    <p><strong>Sanity checks и варианты решения:</strong></p>
                    <ul>
                        <li>Проверить, нет ли контрольных групп/регионов, где, например, запускалась только кампания без редизайна или наоборот.</li>
                        <li>Если таких групп нет, честно признать, что чисто идентифицировать отдельный эффект редизайна невозможно.</li>
                        <li>В отчёте явно разделить «эффект пакета изменений» и невозможность декомпозиции на компоненты.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> приписать весь наблюдаемый uplift или падение редизайну, хотя он может быть в основном вызван маркетинговой кампанией или увеличением цен.</p>
                </div>
            </details>
        </div>

        <!-- Task 11 -->
        <div class="task-card">
            <div class="task-title">Задача 11. Placebo тест для DiD</div>
            <div class="task-body">
                <p>Ваш DiD-анализ даёт +8% к выручке после запуска новой программы лояльности в Москве относительно контрольных городов.</p>
                <p>Результат выглядит красиво, но вы хотите убедиться, что он не артефакт модели и выбора контрольной группы.</p>
                <p>У вас есть данные ещё за полгода до реального запуска программы.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемые проверки (placebo-тесты):</strong></p>
                    <ul>
                        <li>Поставить ложную дату «запуска» на несколько месяцев раньше и посчитать DiD только на pre-period. Эффект должен быть близок к 0.</li>
                        <li>Поменять местами роли городов: считать, как будто в СПб запускали программу, а Москва — контроль. Эффект должен быть близок к 0.</li>
                        <li>Подобрать альтернативный набор контрольных городов с похожими трендами и проверить, сохраняется ли оценка эффекта по порядка величины.</li>
                    </ul>
                    <p><strong>Ключевая идея:</strong> если метод систематически выдаёт значимые эффекты в местах, где их заведомо нет, доверять оценке +8% нельзя.</p>
                    <p><strong>Главный риск:</strong> «выученная» модель трендов, которая при любом сдвиге даёт красивый uplift, не отражающий реальный эффект программы лояльности.</p>
                </div>
            </details>
        </div>

        <!-- Task 12 -->
        <div class="task-card">
            <div class="task-title">Задача 12. Selection on unobservables ⚠</div>
            <div class="task-body">
                <p>Компания выдала персональные скидки пользователям, которые пожаловались в поддержку на качество сервиса.</p>
                <p>Вы собрали matching по tenure, прошлой выручке, устройству, региону и посчитали uplift по удержанию: +20% в treated-группе.</p>
                <p>Продуктовая команда хочет использовать этот результат, чтобы оправдать масштабирование скидок.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Проблема:</strong> сильная селекция по немеряемым факторам. Пользователи, которые жалуются, могут одновременно быть более вовлечёнными (заботятся о сервисе) и более фрустрированными. Matching по наблюдаемым признакам этого не устраняет.</p>
                    <p><strong>Ключевое допущение matching (selection on observables):</strong> все факторы, влияющие на попадание в treatment и на исход, измерены и учтены в модели. Здесь это явным образом нарушено.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Сравнить динамику поведения жалующихся и не жалующихся пользователей в долгую до скидки.</li>
                        <li>Попробовать найти «квази-контроль» среди пользователей, обращавшихся в поддержку по другим поводам, но не получивших скидку.</li>
                        <li>Оценить, насколько реалистично, что весь uplift 20% объясняется именно скидкой, а не разными типами пользователей.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> серьёзное завышение эффекта скидок и дорогостоящее масштабирование неэффективной механики. В таких кейсах лучше стремиться к RCT (A/B среди жалующихся) или использовать инструменты (IV) вместо чистого matching.</p>
                </div>
            </details>
        </div>

        <!-- Task 13 -->
        <div class="task-card">
            <div class="task-title">Задача 13. Diff-in-Diff с несколькими treatment периодами</div>
            <div class="task-body">
                <p>Фича rollout-ится по городам волнами: 3 города в январе, ещё 3 в марте, ещё 3 в мае. Ещё 6 городов остаются на старой версии весь год.</p>
                <p>У вас есть помесячные данные по метрикам по всем городам за 2 года.</p>
                <p>Нужно оценить общий эффект фичи и понять, нет ли сдвига эффекта между волнами.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Рекомендуемый метод:</strong> DiD с разными timing-ами treatment (staggered adoption). На практике — двухфакторная регрессия с fixed effects по городам и времени или более аккуратные методы типа Callaway–Sant’Anna / Sun–Abraham.</p>
                    <p><strong>Ключевые допущения:</strong> параллельные тренды для каждой волны относительно её контролей; отсутствие сильных carryover-эффектов между волнами, неучтённых в модели.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Проверить pre-тренды по каждому набору городов, которые входят в конкретную волну.</li>
                        <li>Сравнить результаты разных спецификаций (простая 2×FE vs современные методы для staggered DiD).</li>
                        <li>Посмотреть event-study графики: динамика эффекта по месяцам от момента включения для каждой волны.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> использование наивной двухфакторной модели при разном timing-е может приводить к смещённым оценкам, особенно если эффект со временем меняется; важно использовать корректные методы для staggered DiD.</p>
                </div>
            </details>
        </div>

        <!-- Task 14 -->
        <div class="task-card">
            <div class="task-title">Задача 14. Когда квази-эксперимент лучше не делать</div>
            <div class="task-body">
                <p>Год назад компания полностью мигрировала платформу на новую архитектуру. Миграция заняла несколько месяцев, выкатывалась по кускам.</p>
                <p>Сейчас CEO просит «доказать», что миграция улучшила бизнес-метрики. Однако до миграции метрики практически не трекались: есть только очень агрегированные ежеквартальные отчёты.</p>
                <p>Вы пытаетесь придумать DiD, ITS или synthetic control, но понимаете, что данных до изменений почти нет.</p>
            </div>
            <details>
                <summary>Ответ</summary>
                <div class="task-answer">
                    <p><strong>Честный вывод:</strong> при отсутствии нормальных pre-period данных полноценный квази-эксперимент провести нельзя. ITS требует истории ряда до интервенции, DiD — сравнения трендов до и после, synthetic control — качественного pre-period fit.</p>
                    <p><strong>Ключевое допущение большинства методов:</strong> наличие информативного периода <em>до</em> изменения, который позволяет построить контрфактуал. Здесь оно не выполняется.</p>
                    <p><strong>Sanity checks:</strong></p>
                    <ul>
                        <li>Проверить, нет ли хотя бы грубых исторических данных (по регионам, каналам), которые можно было бы использовать для очень приблизительного анализа.</li>
                        <li>Попробовать оценить только операционные метрики «после» (например, стабильность, скорость релизов), но не каузальный эффект на выручку.</li>
                        <li>Сразу заложить правильный сбор метрик для будущих крупных изменений, чтобы такая ситуация не повторилась.</li>
                    </ul>
                    <p><strong>Главный риск:</strong> попытаться «натянуть» квази-эксперимент на несуществующие данные и выдать псевдокаузальный вывод. Важно суметь сказать «мы не можем честно оценить эффект миграции» и предложить альтернативные метрики успеха.</p>
                </div>
            </details>
        </div>

        <nav class="module-nav">
            <a href="../07_common_mistakes/index.html">← Предыдущий модуль</a>
            <a href="../../index.html">К курсу</a>
            <span class="nav-disabled">Следующий модуль →</span>
        </nav>
    </div>
</body>
</html>

