# Практика — Распределения

Для каждой задачи:
- **(a)** Определите форму распределения
- **(b)** Назовите ключевой риск для A/B-теста
- **(c)** Предложите подход

Ответы — после каждой задачи.

---

## Задача 1. Revenue per user в e-commerce

**Данные:** 100K пользователей. 78% = 0₽, 18% = 50–500₽, 3% = 500–5000₽, 1% = 5000–80 000₽. Среднее = 120₽, медиана = 0₽. Топ-1% = 42% суммарной выручки. Нужно обнаружить +5% эффект в A/B-тесте.

### Ответ

**Форма:** zero-inflated + heavy tail (Pareto-like правый хвост). Двухкомпонентная смесь: нулевой процесс (не купил) + тяжёлохвостое распределение чеков.

**Риск:** t-test нестабилен — несколько whale users определяют среднее. p-value будет «прыгать» при повторных запусках. Power analysis на основе нормального предположения завысит мощность.

**Подход:** (1) Разделить на CR (proportion, z-test) + revenue среди покупателей (bootstrap/winsorization). (2) Если нужна единая метрика — bootstrap с winsorization на P99. (3) CUPED с pre-period revenue (если доступен).

---

## Задача 2. CTR рекламных баннеров

**Данные:** 5M показов. Каждый показ — клик (1) или нет (0). CTR ≈ 2.1%. Нужно обнаружить +0.1 п.п. (абсолютный рост).

### Ответ

**Форма:** Bernoulli на уровне показа, биномиальное в агрегации.

**Риск:** минимальный для формы — CLT работает быстро для биномиальных данных при N = 5M. Главный риск не в распределении, а в дизайне: treatment-affected exposure (если treatment меняет число показов на пользователя).

**Подход:** z-test для долей. При 5M показов и целевом +0.1 п.п. мощность достаточна. Проверить стабильность числа показов между группами.

---

## Задача 3. Время загрузки страницы (latency)

**Данные:** 200K запросов. Медиана = 180ms, среднее = 450ms, P95 = 1200ms, P99 = 8500ms. Распределение: резкий пик в 100–300ms, длинный хвост до 30 секунд. Нужно обнаружить улучшение.

### Ответ

**Форма:** смесь: быстрые запросы (cache hit, CDN) + медленные (backend, cold start). Тяжёлый правый хвост. Возможно — Weibull или смесь двух экспоненциальных.

**Риск:** среднее в 2.5× больше медианы — heavy tail. Несколько запросов >10 секунд двигают среднее непропорционально. t-test на средних нестабилен.

**Подход:** (1) Winsorization на P95 или P99 — ограничить влияние «застрявших» запросов. (2) Анализировать P50 (медиану) и P95 как отдельные метрики — они информативнее среднего. (3) Bootstrap для оценки доверительного интервала.

---

## Задача 4. Число заказов на пользователя (overdispersion)

**Данные:** 50K пользователей за месяц. 60% = 0 заказов, 25% = 1, 10% = 2–3, 5% = 4–20. Среднее = 1.1, дисперсия = 3.4. Нужно обнаружить +10% рост числа заказов.

### Ответ

**Форма:** Zero-inflated Negative Binomial. Overdispersion: дисперсия = 3.4 >> среднее = 1.1 (для Poisson было бы = 1.1). Масса в нуле = 60%.

**Риск:** (1) Zero inflation → мощность t-test падает. (2) Overdispersion → стандартный Poisson-тест завышает значимость.

**Подход:** (1) Разделить на CR (0/1 хотя бы один заказ, z-test) + число заказов среди заказавших (t-test/bootstrap). (2) Welch t-test на всех (работает при N = 50K, но power будет ниже ожидаемого). (3) CUPED с pre-period числом заказов.

---

## Задача 5. LTV 90 дней

**Данные:** 30K пользователей. Медиана = 0₽, среднее = 850₽, P99 = 25 000₽. Gini coefficient ≈ 0.85. Log(LTV + 1) распределение визуально похоже на нормальное для ненулевых.

### Ответ

**Форма:** Zero-inflated log-normal. В log-шкале ненулевые значения — приблизительно нормальные. Gini = 0.85 подтверждает экстремальное неравенство.

**Риск:** (1) Heavy tail: small fraction определяет среднее. (2) Zero inflation: 50%+ нулей. (3) t-test требует огромной выборки для стабильного p-value.

**Подход:** (1) Разделить: CR (z-test) + LTV среди конвертировавших (bootstrap/log-transform). (2) Winsorization на P99. (3) CUPED с pre-period LTV — если когорта не новая. (4) Log1p-трансформация с осторожностью (>50% нулей → log1p нежелателен).

---

## Задача 6. Конверсия 0.3% (редкое событие)

**Данные:** 80K пользователей на группу. Конверсия в подписку = 0.3%. Нужно обнаружить +20% отн. рост (до 0.36%).

### Ответ

**Форма:** Bernoulli с p = 0.003. Ожидаемое число событий ≈ 240 на группу.

**Риск:** при p << 1 нормальная аппроксимация биномиального распределения неточна. z-test может давать некорректные p-value и доверительные интервалы.

**Подход:** (1) Точный тест Фишера (предпочтительнее z-test при малом числе событий). (2) Bootstrap (permutation test). (3) Power analysis: при 240 событиях и +20% отн. рост — проверить, хватает ли мощности (скорее всего нет; нужно 200K+ на группу).

---

## Задача 7. AOV с «нормальными» чеками

**Данные:** AOV = GMV / заказы. 60K пользователей, 90K заказов. Чеки: медиана = 1200₽, среднее = 1350₽, P99 = 4500₽. Распределение чеков — умеренно-скошенное, без экстремальных выбросов. Аналитик хочет применить t-test на поюзерных средних AOV.

### Ответ

**Форма:** ratio двух случайных величин (GMV и число заказов). Хотя распределение чеков умеренное, AOV — не per-user метрика.

**Риск:** t-test на средних AOV по пользователям игнорирует, что знаменатель (число заказов) — случайная величина. Пользователь с 1 заказом и пользователь с 20 заказами вносят одинаковый вес — это некорректно.

**Подход:** Delta-method или линеаризация. При умеренных хвостах — delta-method надёжен при N = 60K. Форма распределения чеков здесь не проблема — проблема в *типе метрики* (ratio).

---

## Задача 8. Bimodal latency (cache hit vs miss)

**Данные:** 500K запросов. Гистограмма: два чётких пика — 50ms и 800ms. Соотношение ~70% / 30%. Нужно оценить эффект новой CDN.

### Ответ

**Форма:** смесь (mixture) двух распределений — cache hit (~50ms) и cache miss (~800ms). Среднее ≈ 275ms — не описывает ни одну из подгрупп.

**Риск:** t-test на среднем неинформативен. Эффект CDN может улучшать только cache miss (→ мода сдвигается с 800ms на 400ms), не затрагивая cache hit. Среднее изменится умеренно, но пользовательский опыт для 30% улучшится радикально.

**Подход:** (1) Анализировать P50 и P95 отдельно. (2) Стратифицировать: cache hit и cache miss как отдельные подгруппы (pre-treatment, не post-treatment!). (3) Бутстреп с раздельными квантильными метриками.

---

## Задача 9. Revenue + winsorization — какой порог?

**Данные:** Revenue per user. Аналитик планирует winsorization перед t-test. Вопрос: P95, P99 или P99.5? Предварительный анализ показывает:
- При P95: effect = +3.2%, p = 0.04
- При P99: effect = +5.1%, p = 0.02
- При P99.5: effect = +7.8%, p = 0.08
- Без winsorization: effect = +12.3%, p = 0.35

### Ответ

**Проблема:** (1) Результат зависит от выбора порога — это degree of freedom для аналитика (p-hacking risk). (2) Без winsorization p-value нестабилен (0.35 → heavy tail). (3) Чем мягче winsorization, тем больше эффект, но больше и дисперсия.

**Риск:** аналитик может (осознанно или нет) выбрать порог, дающий «хороший» p-value.

**Подход:** (1) Зафиксировать порог **до** эксперимента (в analysis plan). (2) Показать все варианты как sensitivity analysis. (3) P99 — стандартный компромисс. (4) Bootstrap как alternative — не зависит от выбора порога.

---

## Задача 10. «Удалим outliers» — почему нельзя

**Данные:** Revenue per user. 3 пользователя с revenue >100K₽ (при среднем 120₽). Аналитик предлагает «удалить outliers» перед тестом. Аргумент: «это боты или ошибки».

### Ответ

**Проблема:** (1) Если это реальные whale users — удаление создаёт downward bias. Treatment мог *создать* этих whale users (промо для крупных клиентов). (2) Если удалять в обеих группах — selection bias: вы удаляете разных пользователей в тесте и контроле. (3) Решение об удалении принимается *после* просмотра данных → p-hacking.

**Риск:** изменение выборки post-hoc нарушает pre-registration. Результат зависит от определения «outlier».

**Подход:** (1) Winsorization (не удаление — замена на P99). (2) Проверить: это боты? → отдельный фильтр по ботам, до анализа. (3) Показать результат с outliers и без — как sensitivity check. (4) Если treatment targeting крупных клиентов — удалять их нельзя категорически.

---

## Задача 11. Log-трансформация с 40% нулей

**Данные:** Revenue per user. 40% = 0₽. Ненулевые — log-normal. Аналитик предлагает log(revenue + 1) и t-test на трансформированных данных.

### Ответ

**Проблема:** (1) log(0 + 1) = 0 → 40% наблюдений «склеиваются» в одной точке. (2) log-трансформация предназначена для непрерывных положительных данных. При 40% нулей распределение log(x+1) — не нормальное (масса в нуле + колокол для ненулевых). (3) Интерпретация: вы тестируете *геометрическое* среднее — но что означает геометрическое среднее, если 40% = 0?

**Риск:** мощность теста снижается. Эффект на ненулевых «разбавляется» массой нулей. Результат трудно интерпретировать бизнесу.

**Подход:** (1) Разделить: CR (z-test) + revenue среди покупателей (log-transform допустим, если нулей <5%). (2) Bootstrap на оригинальных данных (без трансформации). (3) log1p допустим только при <10–15% нулей.

---

## Задача 12. Identical means, different distributions

**Данные:** два варианта checkout. Среднее число шагов до покупки: тест = 3.2, контроль = 3.2. p-value = 0.95. Вывод аналитика: «нет эффекта».

Но: распределение в тесте — бимодальное (пик в 2 и пик в 5). В контроле — нормальное (пик в 3).

### Ответ

**Проблема:** средние одинаковы, но распределения радикально различны. Часть пользователей в тесте проходит checkout быстрее (2 шага), часть — медленнее (5 шагов). Это два разных пользовательских опыта.

**Риск:** t-test и z-test сравнивают только средние. Одинаковые средние не означают одинаковый опыт. Treatment может создавать winners и losers одновременно.

**Подход:** (1) Визуальная диагностика: гистограммы обеих групп. (2) Квантильные тесты: сравнить P25, P50, P75. (3) Kolmogorov-Smirnov тест (H0: распределения одинаковы). (4) Segmentation: кто «выиграл» от нового checkout, кто «проиграл»?

---

## Задача 13. Overdispersion в pushes per user

**Данные:** число push-уведомлений, отправленных пользователю за неделю. Среднее = 12, дисперсия = 180. Нужно тестировать новый алгоритм push-рассылки.

### Ответ

**Форма:** сильная overdispersion (дисперсия в 15× больше среднего). Не Poisson (где var = mean). Negative Binomial или mixture.

**Риск:** (1) Стандартные CI на основе Poisson-предположения будут слишком узкими → ложная значимость. (2) Распределение, вероятно, heavy-tailed: некоторые пользователи получают 100+ pushes.

**Подход:** (1) Welch t-test (допускает unequal variances). (2) Bootstrap для robustness. (3) Проверить: есть ли heavy tail в pushes (P99 vs mean). (4) Рассмотреть winsorization, если whale-users (>100 pushes) сильно влияют на среднее.
