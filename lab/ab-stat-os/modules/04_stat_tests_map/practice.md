# Практика — Карта выбора статкритерия

Для каждого сценария:

- **(a)** Выберите подход к тестированию
- **(b)** Назовите 2 ключевых риска
- **(c)** Назовите 2 проверки, которые нужно сделать перед запуском

Ответы — в конце документа.

---

## Сценарии

### 1. CR в мобильном приложении

**Метрика:** Доля пользователей, совершивших покупку (покупатели / все пользователи).
**Контекст:** Рандомизация по пользователям. 60K на группу. Нет pre-period. Нет кластеров.

### 2. Revenue per user (e-commerce) ⚠

**Метрика:** Суммарная выручка за 14 дней на пользователя (включая нули).
**Контекст:** Рандомизация по пользователям. 120K на группу. 78% пользователей = 0. Топ-0.1% = 35% выручки. Pre-period есть (14 дней до теста).

### 3. AOV (средний чек)

**Метрика:** GMV / количество заказов. Считается глобально.
**Контекст:** Рандомизация по пользователям. 40K на группу. Распределение чеков умеренное (нет экстремальных выбросов). Нет pre-period.

### 4. CTR рекламного баннера ⚠

**Метрика:** Клики / показы. Считается глобально по всем показам.
**Контекст:** Рандомизация по пользователям. 200K на группу. Treatment меняет количество показов на пользователя (новый алгоритм таргетинга). Pre-period недоступен.

### 5. ARPPU (среди покупателей) ⚠

**Метрика:** Средняя выручка на покупателя. Считается только среди пользователей с ≥1 покупкой.
**Контекст:** Рандомизация по пользователям. 80K на группу. Treatment — изменение онбординга. Ожидается рост конверсии (→ больше покупателей). Pre-period есть.

### 6. Число сессий на пользователя

**Метрика:** Среднее количество сессий за 7 дней на пользователя.
**Контекст:** Рандомизация по пользователям. 50K на группу. Распределение умеренно-скошенное (медиана = 3, среднее = 5). Pre-period есть (корреляция pre-post ≈ 0.5).

### 7. Конверсия в гео-эксперименте ⚠

**Метрика:** Доля пользователей с покупкой (покупатели / все пользователи).
**Контекст:** Рандомизация по городам. 18 городов (9 тест, 9 контроль). 500K пользователей суммарно. Нет pre-period.

### 8. Refund rate

**Метрика:** Количество возвратов / количество заказов. Каждый заказ — либо возвращён, либо нет.
**Контекст:** Рандомизация по пользователям. 30K на группу. Доля возвратов ~4%. Нет кластеров. Нет pre-period.

### 9. RPM (Revenue Per Mille)

**Метрика:** Рекламная выручка / количество показов × 1000. Ratio-метрика.
**Контекст:** Рандомизация по пользователям. 15K на группу. Heavy tail в рекламной выручке (programmatic). Нет pre-period.

### 10. Retention Day 7

**Метрика:** Доля пользователей, вернувшихся на 7-й день после регистрации.
**Контекст:** Рандомизация по пользователям. 25K на группу. Только новые пользователи (pre-period невозможен). Нет кластеров.

### 11. Стоимость доставки на заказ

**Метрика:** Общая стоимость доставки / количество заказов. Ratio-метрика.
**Контекст:** Рандомизация по пользователям. 70K на группу. Без heavy tail (стоимость доставки ограничена сверху). Pre-period 2 недели. Нет кластеров.

### 12. Конверсия среди увидевших paywall ⚠

**Метрика:** Доля пользователей, оформивших подписку, среди тех, кто увидел paywall.
**Контекст:** Рандомизация по пользователям. 90K на группу. Treatment меняет, когда показывается paywall (→ разный состав «увидевших»). Pre-period недоступен.

---

## Ответы

### 1. CR в мобильном приложении

**Подход:** z-test для долей.
**Риски:** (1) Минимальные — стандартный случай. (2) При очень низкой конверсии (<0.5%) нормальная аппроксимация может быть неточной.
**Проверки:** (1) Единица рандомизации = единица анализа (пользователь). (2) Выборка достаточна для целевого MDE.

### 2. Revenue per user (e-commerce) ⚠

**Подход:** Bootstrap + winsorization + CUPED.
**Риски:** (1) Heavy tail: 0.1% пользователей определяют 35% метрики → t-test нестабилен. (2) Zero inflation: 78% нулей завышают дисперсию.
**Проверки:** (1) Winsorization на 99-м перцентиле стабилизирует? (2) CUPED: корреляция pre-post достаточна (>0.3)?
**Ловушка:** t-test без обработки хвостов даст нестабильный p-value, который не воспроизводится при повторном запуске.

### 3. AOV (средний чек)

**Подход:** Delta-method / линеаризация.
**Риски:** (1) Знаменатель (число заказов) — случайная величина; наивный t-test на средних AOV по пользователям некорректен. (2) Если treatment влияет на число заказов — знаменатель зависит от treatment.
**Проверки:** (1) Проверить, что хвосты распределения чеков действительно умеренные (Q-Q plot). (2) Проверить стабильность знаменателя между группами.

### 4. CTR рекламного баннера ⚠

**Подход:** z-test для долей (CTR — это доля: каждый показ → клик/не клик).
**Риски:** (1) Treatment-affected exposure: алгоритм таргетинга меняет число показов на пользователя → знаменатель зависит от treatment. (2) Нарушение независимости: несколько показов одному пользователю скоррелированы.
**Проверки:** (1) Сравнить среднее число показов на пользователя между группами. (2) Рассмотреть кластеризацию по пользователям (или агрегацию до per-user CTR).
**Ловушка:** если treatment увеличивает число показов, CTR может снижаться даже при росте кликов — эффект разбавления.

### 5. ARPPU (среди покупателей) ⚠

**Подход:** Двухэтапная процедура / регрессия с коррекцией.
**Риски:** (1) Selection bias: treatment увеличивает конверсию → новые покупатели менее платёжеспособны → ARPPU падает даже если выручка растёт. (2) CUPED ограниченно применим: новые покупатели не имели pre-period покупок.
**Проверки:** (1) Сравнить конверсию между группами (изменился ли состав подвыборки?). (2) Посмотреть на total revenue (неусловная метрика) как sanity check.
**Ловушка:** ARPPU упал → аналитик решает, что treatment вреден. На самом деле выручка выросла, просто состав покупателей сместился.

### 6. Число сессий на пользователя

**Подход:** Welch t-test + CUPED.
**Риски:** (1) Умеренная скошенность (медиана ≠ среднее). (2) Pre-period дрейф: если активность менялась перед экспериментом, ковариата шумит.
**Проверки:** (1) Гистограмма распределения — нужен ли bootstrap? (2) CUPED: проверить корреляцию pre-post ≈ 0.5 → ожидаемое снижение дисперсии ~25%.

### 7. Конверсия в гео-эксперименте ⚠

**Подход:** z-test + cluster-robust SE (или randomization inference).
**Риски:** (1) 18 кластеров — мало для cluster-robust SE (нужно ≥30-50). (2) Эффективный N ≈ 18, не 500K → реальная мощность критически низкая.
**Проверки:** (1) Оценить ICC и design effect. (2) Рассмотреть wild cluster bootstrap или randomization inference вместо асимптотических SE.
**Ловушка:** z-test с N = 500K показывает p = 0.0001. Аналитик уверенно запускает. Cluster-robust p = 0.22. Мощность была ~15%.

### 8. Refund rate

**Подход:** z-test для долей.
**Риски:** (1) Минимальные — каждый заказ либо возвращён, либо нет (proportion). (2) При доле 4% и 30K нужно проверить, что MDE реалистичен.
**Проверки:** (1) Power analysis: при доле 4% и 30K на группу — какой минимальный эффект детектируется? (2) Единица анализа (заказ) ≠ единица рандомизации (пользователь) — нет ли корреляции между заказами одного пользователя?

### 9. RPM (Revenue Per Mille)

**Подход:** Bootstrap отношения.
**Риски:** (1) Heavy tail в рекламной выручке → delta-method нестабилен. (2) Малая выборка (15K) усиливает чувствительность к выбросам.
**Проверки:** (1) Гистограмма распределения выручки — какой процент в хвосте? (2) Рассмотреть winsorization числителя перед bootstrap.

### 10. Retention Day 7

**Подход:** z-test для долей.
**Риски:** (1) Минимальные — бинарная метрика (вернулся / не вернулся). (2) Если treatment влияет на регистрацию (change in signup flow) → состав когорты зависит от treatment.
**Проверки:** (1) Проверить, что treatment не влияет на сам процесс регистрации. (2) Power analysis: retention ~20–40%, 25K на группу — достаточно для MDE ≥ 1–2 п.п.

### 11. Стоимость доставки на заказ

**Подход:** Delta-method + CUPED.
**Риски:** (1) Ratio-метрика: знаменатель (число заказов) — случайная величина. (2) Если treatment влияет на число заказов — знаменатель treatment-affected.
**Проверки:** (1) Проверить, что число заказов стабильно между группами. (2) CUPED: pre-period стоимость доставки коррелирует с post-period? Если корреляция >0.3 → применяем.

### 12. Конверсия среди увидевших paywall ⚠

**Подход:** Двухэтапная процедура / ITT-метрика.
**Риски:** (1) Selection bias: treatment меняет, кто увидит paywall → разный состав «увидевших». (2) Наивное сравнение долей среди увидевших даёт смещённую оценку.
**Проверки:** (1) Сравнить долю пользователей, увидевших paywall, между группами (изменилась ли экспозиция?). (2) Рассмотреть ITT-метрику (конверсия среди ВСЕХ пользователей) как основную.
**Ловушка:** конверсия среди увидевших paywall выросла. Но treatment показал paywall менее активным пользователям → те, кто увидел, уже мотивированы → это не каузальный эффект, а selection.
