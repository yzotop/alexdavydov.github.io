# Модуль 05 — Ускорение тестов

## 1. Почему тесты «долго считаются»

### Что такое variance в A/B

Variance (дисперсия) — мера шума в данных. Чем выше дисперсия метрики, тем сложнее отличить реальный эффект от случайного колебания.

Revenue per user: среднее = 120₽, SD = 800₽. Эффект +5% = +6₽. Шум в 130× больше сигнала. Чтобы t-test увидел этот эффект — нужны сотни тысяч пользователей.

Конверсия 5%: SD = √(0.05 × 0.95) ≈ 0.22. Эффект +1 п.п. = 0.01. Шум в 22× больше сигнала — но это уже лучше, чем revenue. Поэтому тесты на конверсию быстрее.

### Почему power = функция дисперсии

Power (мощность) — вероятность обнаружить реальный эффект. Формула упрощённо:

**n ∝ σ² / δ²**

где σ² — дисперсия метрики, δ — размер эффекта. Удвоить выборку — дорого (время × трафик). Уменьшить дисперсию вдвое — эквивалент удвоения выборки, но бесплатно.

### Как variance влияет на MDE и длительность

MDE (Minimal Detectable Effect) — минимальный эффект, который тест может обнаружить при заданных N и power.

**MDE ∝ σ / √n**

Если снизить дисперсию на 40%:
- MDE падает на ~23% (√0.6 ≈ 0.77)
- Или: тот же MDE достигается в 1.7× меньшей выборке
- Или: тест заканчивается в 1.7× быстрее

Это не теория — это операционный рычаг. Команда, использующая CUPED, запускает в 1.5–2× больше экспериментов в год при том же трафике.

---

## 2. Основная идея ускорения

### Не увеличивать трафик, а уменьшать шум

Три стратегии ускорения:

1. **Больше трафика** — дорого, ограничено продуктом
2. **Больший эффект** — не контролируемо (зависит от фичи)
3. **Меньше шума** — бесплатно, контролируемо, масштабируемо

Variance reduction — это третья стратегия. Мы не меняем данные, а убираем из них компоненту шума, которая не связана с treatment.

### Разделить signal и noise

Метрика Y = treatment_effect + user_baseline + random_noise.

Treatment effect — то, что мы ищем. User baseline — то, что было бы без эксперимента (пользователь и так тратит 200₽ в месяц). Random noise — случайные колебания.

Если мы знаем user_baseline (из pre-period данных), мы можем вычесть его:

**Y_adj = Y − θ · X_pre**

Остаётся: treatment_effect + остаточный_noise. Дисперсия Y_adj < дисперсия Y.

---

## 3. CUPED — интуиция

### Pre-period как ковариата

CUPED (Controlled-experiment Using Pre-Experiment Data) использует данные *до* эксперимента как ковариату. Если пользователь тратил 200₽/мес до эксперимента, вероятно, он потратит примерно столько же и во время — плюс-минус эффект treatment.

Ковариата X_pre не зависит от treatment (собрана до начала). Поэтому её вычитание не вносит bias.

### Корреляция до/после

Ключевой параметр — корреляция ρ между X_pre и Y:

**Variance reduction = ρ²**

| ρ (корреляция) | Снижение дисперсии | Эквивалент в трафике |
|---|---|---|
| 0.3 | 9% | 1.1× |
| 0.5 | 25% | 1.3× |
| 0.7 | 49% | 2× |
| 0.9 | 81% | 5× |

При ρ = 0.7 вы получаете эффект удвоения выборки — бесплатно. При ρ = 0.9 — пятикратное увеличение.

### Когда CUPED работает

- Метрика стабильна во времени (revenue, число сессий, engagement)
- Pre-period ≥ 1–2 недели (достаточно для стабильной оценки)
- Нет тренда или сезонности в pre-period (или она одинакова в обеих группах)
- Пользователь присутствует и в pre- и в post-period

### Когда CUPED не работает или опасен

- **Новые пользователи:** нет pre-period → CUPED неприменим
- **Conditional-метрика:** состав подвыборки зависит от treatment → ковариата невалидна (Модуль 01, 02)
- **Ковариата зависит от treatment:** если X_pre измерена *после* start, но *до* exposure — это leakage
- **Низкая корреляция (ρ < 0.2):** выигрыш <4% — не стоит усложнения
- **Дрейф метрики:** если метрика нестационарна, pre-period ковариата шумит

### Риск data leakage

Leakage — когда ковариата содержит информацию о treatment. Это происходит если:
- Pre-period пересекается с периодом эксперимента
- Ковариата включает данные «дня запуска» (ramp-up эффект)
- Ковариата — агрегат, включающий post-treatment наблюдения

**Правило:** X_pre должен быть полностью собран *до* начала рандомизации. Ни одно наблюдение из X_pre не должно включать данные после assignment.

---

## 4. Стратификация и блокировка

### Когда группы неоднородны

Если в эксперименте смешаны пользователи из разных сегментов (new vs returning, mobile vs desktop, город A vs город B) — дисперсия внутри каждого сегмента ниже, чем общая.

Стратификация — разбиение выборки на страты (блоки) и балансировка treatment/control внутри каждой страты.

### Пример: города, сегменты, device

Доставка еды. Средний чек: Москва = 1800₽, регионы = 700₽. Общая дисперсия высокая. Если стратифицировать по городу — дисперсия внутри страт снижается на 15–30%.

Device: desktop users конвертируются в 3× чаще, чем mobile. Стратификация по device type убирает эту компоненту дисперсии.

### Ошибки стратификации

1. **Post-treatment стратификация.** Нельзя стратифицировать по переменной, зависящей от treatment (число визитов *во время* теста). Только по pre-treatment характеристикам.
2. **Слишком много страт.** При 100+ стратах и малом N некоторые страты будут пустыми. Оптимально: 5–20 страт.
3. **Стратификация без учёта в анализе.** Если стратифицировали при рандомизации — анализ должен это учитывать (страт-специфические оценки + взвешивание).

---

## 5. Тримминг и winsorization

### Heavy tail — что делать с шумом от хвоста

Revenue per user. 0.1% пользователей генерируют 30–40% дисперсии. Один whale user может изменить среднее группы на 1–2%. Это шум, не сигнал.

### Что мы «режем»

- **Winsorization:** значения выше P99 заменяются на P99. Наблюдения сохраняются, но хвост «обрезается».
- **Trimming:** значения выше P99 удаляются. Теряем наблюдения, но среднее стабильнее.
- **Log-transform:** сжимает правый хвост. Но меняет интерпретацию (геометрическое среднее).

### Когда это искажает эффект

Если treatment создаёт whale users (premium-фича, enterprise deal) — winsorization *скрывает* реальный эффект. Вы «режете» именно то, что treatment создал.

**Правило:** (1) Зафиксировать порог до эксперимента. (2) Показывать результат с и без winsorization — sensitivity analysis. (3) Если бизнес-ценность в хвосте (enterprise) — winsorization неуместна.

Типичная дилемма: winsorization снижает дисперсию на 40%, но занижает эффект на 15%. Стоит ли? Зависит от контекста — универсального ответа нет.

---

## 6. Регрессия и ковариаты

### Регрессионная корректировка

CUPED — частный случай регрессионной корректировки с одной ковариатой. В общем случае:

**Y_adj = Y − Σ θ_k · X_k**

где X_k — ковариаты (pre-period метрика, сегмент, device, регион).

Множественные ковариаты могут дать больший выигрыш, чем одна. Pre-period revenue + pre-period sessions + device type → совокупное снижение дисперсии 50–60%.

### Множественные ковариаты

Каждая дополнительная ковариата добавляет incremental gain — но с убывающей отдачей. Первая ковариата (pre-period метрика) даёт 80% выигрыша. Вторая — ещё 10%. Третья — ещё 3%.

**Практика:** 1–3 ковариаты — sweet spot. Больше — переобучение и diminishing returns.

### Переобучение и p-hacking

Если ковариаты выбирать *после* просмотра результатов — это p-hacking. Аналитик может подобрать набор ковариат, при котором результат «значимый».

**Правило:** ковариаты фиксируются в analysis plan *до* начала эксперимента. Любое отклонение — sensitivity analysis, не primary result.

---

## 7. Практическая таблица решений

| Ситуация | Метод | Ожидаемый выигрыш | Риски |
|---|---|---|---|
| Есть pre-period, ρ > 0.5 | **CUPED** | 25–80% снижения дисперсии | Leakage, нестационарность |
| Есть pre-period, ρ < 0.3 | CUPED даёт мало (<9%) | — | Не стоит усложнения |
| Heavy tail (revenue, LTV) | **Winsorization + bootstrap** | 20–50% стабилизации | Скрывает эффект в хвосте |
| Гетерогенность (city, device) | **Стратификация** | 10–30% снижения дисперсии | Post-treatment стратификация |
| Много нулей (zero inflation) | Разделение метрики (CR + mean) | Кратный рост power | Две метрики вместо одной |
| Conditional-метрика | CUPED ограничен | — | Selection bias (Модуль 01) |
| Новые пользователи | Стратификация (device, source) | 5–15% | CUPED неприменим |

### Комбинирование методов

Методы не исключают друг друга. Типичный стек:

1. **Winsorization** (P99) → убрать шум хвоста
2. **CUPED** (pre-period) → вычесть baseline
3. **Стратификация** (device) → убрать гетерогенность

Совокупный эффект: дисперсия снижается на 50–70%. Тест, который занимал 4 недели, занимает 10–14 дней.

**Связь с другими модулями:**
- Форма распределения → [Distribution Playground](../../simulators/distribution_playground/index.html) (Модуль 03)
- Выбор теста → [Test Selection Map](../../simulators/test_selection_map/index.html) (Модуль 04)
- CUPED в действии → [CUPED Simulator](../../simulators/cuped_simulator/index.html)
