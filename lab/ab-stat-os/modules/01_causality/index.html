<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Модуль 1. Каузальность — Статистика A/B-тестирования</title>
    <link rel="stylesheet" href="../../assets/style.css">
</head>
<body>
    <div class="container">
        <div class="breadcrumbs">
            <a href="../../../../courses/index.html">Все курсы</a> /
            <a href="../../index.html">Статистика A/B-тестирования</a> / Модуль 1
        </div>

        <div class="nav-links">
            <a href="./index.html" class="active">Модуль</a>
            <a href="./practice.html">Практика</a>
            <a href="./simulators.html">Симуляторы</a>
        </div>

        <h1>Модуль 1. Каузальность</h1>

        <!-- Section 1 -->
        <section class="section">
            <h2>1. Почему A/B — это про каузальность, а не сравнение средних</h2>

            <p>
                Большинство аналитиков воспринимают A/B-тест как «сравнить средние двух групп». Это описание механики, но не сути. Суть — в каузальности: <em>этот эффект вызван нашим изменением, а не чем-то ещё?</em>
            </p>

            <h3>Корреляция ≠ причинность</h3>
            <p>
                Пользователи, видевшие промо-баннер, покупают чаще. Это не значит, что баннер увеличивает покупки — возможно, промо показывается активным пользователям, которые и так бы купили. Без рандомизации мы не отличим эффект баннера от эффекта отбора.
            </p>

            <h3>Рандомизация создаёт контрфактуальный баланс</h3>
            <p>
                A/B-тест решает эту проблему: рандомизация делает группы <strong>одинаковыми по всем признакам</strong> — наблюдаемым и ненаблюдаемым — <em>до</em> применения treatment. Единственное, что систематически различается — сам treatment.
            </p>
            <p>
                Если после treatment среднее метрики в группах различается, мы можем утверждать: <em>это различие вызвано treatment</em>. Это каузальное утверждение, а не статистическое.
            </p>

            <h3>Potential outcomes framework</h3>
            <p>Для каждого пользователя i существуют два потенциальных исхода:</p>
            <ul>
                <li><strong>Y<sub>i</sub>(1)</strong> — значение метрики, если пользователь получил treatment</li>
                <li><strong>Y<sub>i</sub>(0)</strong> — значение метрики, если пользователь остался в контроле</li>
            </ul>

            <div class="formula">
                Индивидуальный эффект: &tau;<sub>i</sub> = Y<sub>i</sub>(1) &minus; Y<sub>i</sub>(0)
            </div>

            <p>
                Проблема: мы никогда не наблюдаем оба исхода для одного пользователя. Это <em>fundamental problem of causal inference</em>.
            </p>

            <h3>Числовой пример</h3>
            <table>
                <thead>
                    <tr><th>Пользователь</th><th>Y(0)</th><th>Y(1)</th><th>&tau;<sub>i</sub></th></tr>
                </thead>
                <tbody>
                    <tr><td>A</td><td>100&thinsp;₽</td><td>120&thinsp;₽</td><td>+20&thinsp;₽</td></tr>
                    <tr><td>B</td><td>50&thinsp;₽</td><td>45&thinsp;₽</td><td>&minus;5&thinsp;₽</td></tr>
                    <tr><td>C</td><td>200&thinsp;₽</td><td>230&thinsp;₽</td><td>+30&thinsp;₽</td></tr>
                    <tr><td>D</td><td>0&thinsp;₽</td><td>0&thinsp;₽</td><td>0&thinsp;₽</td></tr>
                </tbody>
            </table>

            <div class="formula">ATE = (20 &minus; 5 + 30 + 0) / 4 = +11.25&thinsp;₽</div>

            <p>
                Мы не можем вычислить ATE напрямую (мы видим только одну колонку на пользователя), но рандомизация позволяет оценить ATE через разность средних между группами.
            </p>
        </section>

        <!-- Section 2 -->
        <section class="section">
            <h2>2. Потенциальные исходы</h2>

            <h3>Что мы оцениваем</h3>

            <div class="formula">Average Treatment Effect (ATE): &tau; = E[Y(1)] &minus; E[Y(0)]</div>

            <p>
                ATE — это среднее по всем пользователям. Оно не говорит, что эффект одинаков для всех. Пользователь A получил +20&thinsp;₽, пользователь B потерял 5&thinsp;₽ — но в среднем treatment полезен.
            </p>

            <h3>Почему нельзя наблюдать оба состояния</h3>
            <p>
                Когда пользователь попал в тест-группу, мы видим Y<sub>i</sub>(1). Что было бы без treatment (Y<sub>i</sub>(0)) — мы не знаем. Это не проблема данных, а фундаментальное ограничение: один человек не может одновременно получить и не получить treatment.
            </p>
            <p>
                Рандомизация обходит это: контрольная группа — статистический заменитель контрфактуального состояния тестовой группы. Они неидентичны поюзерно, но одинаковы в среднем.
            </p>

            <h3>ATT и ATE — не одно и то же</h3>
            <ul>
                <li><strong>ATE</strong> — средний эффект по всей популяции</li>
                <li><strong>ATT</strong> (Average Treatment on the Treated) — средний эффект только среди получивших treatment</li>
            </ul>
            <p>
                При корректной рандомизации ATE = ATT. Но при selection bias (нерандомизированная выборка, conditional-метрика) они расходятся.
            </p>
        </section>

        <!-- Section 3 -->
        <section class="section">
            <h2>3. Три условия каузальности в A/B</h2>

            <h3>Условие 1: Рандомизация (Random Assignment)</h3>
            <p>
                <strong>Определение:</strong> каждый пользователь с равной вероятностью попадает в тест или контроль, независимо от своих характеристик.
            </p>
            <p>
                <strong>Продуктовый пример:</strong> split на уровне user_id через хеш-функцию. <code>hash(user_id, salt) % 100 &lt; 50</code> &rarr; тест.
            </p>
            <div class="callout callout-warn">
                <p><strong>Что ломается при нарушении:</strong> если в тест попадают более активные пользователи — разница между группами отражает не treatment, а исходную неоднородность. Вы измеряете selection bias, а не каузальный эффект.</p>
            </div>

            <h3>Условие 2: Отсутствие интерференции (SUTVA)</h3>
            <p>
                <strong>Определение:</strong> потенциальный исход пользователя i зависит только от его собственного treatment-статуса, а не от treatment-статуса других пользователей.
            </p>
            <p>
                <strong>Продуктовый пример (нарушение):</strong> маркетплейс. Продавец в тест-группе получает новый алгоритм ранжирования &rarr; его товары показываются чаще &rarr; продавцы в контроле теряют показы. Эффект одного пользователя «переливается» в результат другого.
            </p>
            <div class="callout callout-warn">
                <p><strong>Что ломается при нарушении:</strong> ATE смещён. Если treatment одних улучшает метрику за счёт других, наивная оценка завышает реальный эффект. В пределе — zero-sum: суммарного эффекта нет, но A/B-тест показывает значимость.</p>
            </div>

            <h3>Условие 3: Консистентность (Consistency)</h3>
            <p>
                <strong>Определение:</strong> наблюдаемый исход равен потенциальному исходу для назначенного treatment. Y<sub>obs</sub> = Y(1) если treatment = 1, Y<sub>obs</sub> = Y(0) если treatment = 0.
            </p>
            <p>
                <strong>Продуктовый пример (нарушение):</strong> эксперимент включает новую фичу, но из-за бага 15% пользователей тест-группы видят старую версию. Наблюдаемый Y для этих пользователей — не Y(1) и не Y(0), а что-то среднее.
            </p>
            <div class="callout callout-warn">
                <p><strong>Что ломается при нарушении:</strong> эффект размывается (attenuation bias). ITT-оценка (Intent-to-Treat) занижает реальный эффект, потому что часть тестовой группы фактически не получила treatment.</p>
            </div>
        </section>

        <!-- Section 4 -->
        <section class="section">
            <h2>4. Единица рандомизации vs единица анализа</h2>

            <h3>Почему это важно</h3>
            <p>
                Единица рандомизации — на каком уровне мы назначаем treatment. Единица анализа — на каком уровне мы измеряем метрику. Если они не совпадают, возникают проблемы с корреляцией и интерпретацией.
            </p>

            <h3>User-level рандомизация</h3>
            <p>
                Стандарт: рандомизация по user_id. Один пользователь = одно наблюдение в анализе. Метрики: CR, число сессий, revenue per user — всё агрегируется до пользователя.
            </p>

            <h3>Order-level проблема</h3>
            <p>
                AOV = GMV / заказы. Рандомизация по пользователям, но метрика — на уровне заказа. У одного пользователя может быть 1 заказ или 50. Наблюдения (заказы) от одного пользователя скоррелированы &rarr; наивный t-test на заказах занижает дисперсию.
            </p>
            <div class="callout">
                <p><strong>Решение:</strong> агрегировать до пользователя (delta-method для ratio) или учитывать кластерную структуру (cluster-robust SE с кластером = user).</p>
            </div>

            <h3>Impression-level ловушка</h3>
            <p>
                CTR = клики / показы. Рандомизация по пользователям, но метрика — на уровне показа. Один пользователь генерирует 10–1000 показов. Показы одного пользователя не независимы.
            </p>
            <p>
                <strong>Дополнительная опасность:</strong> treatment может влиять на число показов (treatment-affected exposure). Если алгоритм меняет частоту показов, CTR&nbsp;= clicks/impressions может снижаться даже при росте кликов — эффект разбавления.
            </p>
            <div class="callout">
                <p><strong>Решение:</strong> (1) Агрегировать до per-user CTR. (2) Анализировать clicks и impressions как отдельные метрики. (3) Проверить стабильность числа показов между группами.</p>
            </div>
        </section>

        <!-- Section 5 -->
        <section class="section">
            <h2>5. Кластерная рандомизация</h2>

            <h3>Когда нужна</h3>
            <p>Когда SUTVA нарушена на уровне пользователя — эффект «переливается» между пользователями. Типичные ситуации:</p>
            <ul>
                <li><strong>Гео-эксперименты:</strong> ценовое изменение в одном городе не затрагивает другие города</li>
                <li><strong>Магазины:</strong> рандомизация по точкам продаж</li>
                <li><strong>Команды / группы:</strong> организационные изменения, чат-функции</li>
            </ul>

            <h3>Что меняется</h3>
            <ul>
                <li>Эффективный размер выборки &asymp; число кластеров (не пользователей)</li>
                <li>Внутрикластерная корреляция (ICC) раздувает дисперсию</li>
                <li>Стандартный z-test/t-test драматически занижает p-value</li>
            </ul>

            <h3>ICC — интуиция</h3>
            <p>
                ICC (Intra-Cluster Correlation) — доля общей дисперсии, объяснённая принадлежностью к кластеру.
            </p>

            <div class="formula">
                Design Effect &asymp; 1 + (m &minus; 1) &times; ICC
            </div>

            <p>
                Если ICC&nbsp;= 0.05 и средний кластер = 1000 пользователей, design effect &asymp; 51. Это значит, что вам нужно в 51 раз больше пользователей, чем при user-level рандомизации, для той же мощности.
            </p>

            <h3>Практическое следствие</h3>
            <div class="callout callout-warn">
                <p>Гео-эксперимент с 20 городами и 2M пользователей имеет эффективный N &asymp; 20, а не 2M. Если аналитик использует N = 2M в power analysis, он получает power = 99%. Реальная power — 15–20%. Эффект не воспроизводится.</p>
            </div>
        </section>

        <!-- Section 6 -->
        <section class="section">
            <h2>6. Где ломается каузальность</h2>

            <h3>Leakage (утечка treatment)</h3>
            <p>
                Пользователь из контрольной группы видит результаты treatment через другой канал. Пример: эксперимент с новой ценой. Пользователь контроля видит скриншот новой цены в чате друга &rarr; меняет поведение. Контроль «загрязнён» — ATE занижен.
            </p>

            <h3>Интерференция (network effects)</h3>
            <p>
                Двусторонний маркетплейс: treatment для покупателей влияет на продавцов, и наоборот. Социальная сеть: treatment для одного пользователя влияет на контент, который видят его друзья.
            </p>
            <div class="callout">
                <p><strong>Следствие:</strong> ATE включает прямой эффект + spillover. Наивная оценка может как завышать (если spillover положительный), так и занижать (если zero-sum).</p>
            </div>

            <h3>Post-treatment conditioning</h3>
            <p>
                Анализ результатов только среди пользователей, совершивших действие <em>после</em> начала эксперимента. Пример: «средний чек среди покупателей» — ARPPU. Если treatment увеличил конверсию, состав «покупателей» в тесте и контроле различается. Вы сравниваете разные популяции.
            </p>
            <div class="callout callout-warn">
                <p><strong>Правило:</strong> не conditionируйте на post-treatment переменные. Используйте ITT-метрики или двухэтапные процедуры.</p>
            </div>

            <h3>Conditioning on a collider</h3>
            <p>
                Менее очевидный случай. Пример: анализ «конверсия среди активных пользователей», где «активность» зависит и от treatment, и от конверсии. Conditionирование на collider создаёт ложную ассоциацию.
            </p>
            <div class="callout">
                <p><strong>Правило:</strong> перед анализом проверьте — зависит ли ваша подвыборка от treatment? Если да — это conditioning на post-treatment переменную.</p>
            </div>
        </section>

        <!-- Резюме -->
        <div class="learn-block">
            <h3>Резюме</h3>
            <p>
                A/B-тест — единственный надёжный способ установить каузальную связь в продукте. Но только при соблюдении трёх условий: рандомизация, отсутствие интерференции, консистентность.
            </p>
            <p>
                Нарушение любого из них не просто снижает точность — оно делает оценку смещённой. Вы принимаете решение на основе числа, которое систематически отличается от реального эффекта. И никакое увеличение выборки это не исправит.
            </p>
            <p>
                Прежде чем выбирать статкритерий (Модуль 04) — убедитесь, что эксперимент каузален. Это не формальность. Это фундамент.
            </p>
        </div>

        <!-- Preview sections -->
        <section class="preview-section">
            <h2>Практика</h2>
            <ul class="preview-list">
                <li>13 прикладных задач на нарушения каузальности</li>
                <li>SUTVA, leakage, post-treatment conditioning, colliders</li>
                <li>Кластерная рандомизация и survivor bias</li>
            </ul>
            <a href="./practice.html" class="nav-card">Открыть практику</a>
        </section>

        <section class="preview-section">
            <h2>Симуляторы</h2>
            <ul class="preview-list">
                <li>Карта выбора статкритерия — связь дизайна эксперимента и метода анализа</li>
                <li>Cluster Simulator — визуализация ICC и design effect</li>
            </ul>
            <a href="./simulators.html" class="nav-card">Открыть симуляторы</a>
        </section>

        <nav class="module-nav">
            <span class="nav-disabled">← Предыдущий модуль</span>
            <a href="../../index.html">К курсу</a>
            <a href="../02_metric_types/index.html">Следующий модуль →</a>
        </nav>
    </div>
</body>
</html>
